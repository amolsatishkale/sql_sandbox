{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7933cfd5-dcff-4a69-b575-39431e4e2167",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/29 12:04:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/10/29 12:04:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ[\"SPARK_CLASSPATH\"] = \"/opt/spark/jars/postgresql-42.7.0.jar\"\n",
    "\n",
    "# Initialize Spark Session with PostgreSQL JDBC driver (using local JAR)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SQL_Problems_Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/postgresql-42.7.0.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/opt/spark/jars/postgresql-42.7.0.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/opt/spark/jars/postgresql-42.7.0.jar\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce verbosity\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f95b51-fcf7-4cd3-87ca-a37c6dc5f08c",
   "metadata": {},
   "source": [
    "## Configure Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54614ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL configuration:\n",
      "JDBC URL: jdbc:postgresql://postgres:5432/postgres\n",
      "User: postgres\n"
     ]
    }
   ],
   "source": [
    "# PostgreSQL connection configuration\n",
    "postgres_config = {\n",
    "    \"host\": \"postgres\",  # Docker service name\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\"\n",
    "}\n",
    "\n",
    "# JDBC URL for Spark\n",
    "jdbc_url = f\"jdbc:postgresql://{postgres_config['host']}:{postgres_config['port']}/{postgres_config['database']}\"\n",
    "connection_properties = {\n",
    "    \"user\": postgres_config[\"user\"],\n",
    "    \"password\": postgres_config[\"password\"],\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "print(\"PostgreSQL configuration:\")\n",
    "print(f\"JDBC URL: {jdbc_url}\")\n",
    "print(f\"User: {postgres_config['user']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f279e65",
   "metadata": {},
   "source": [
    "## Read table data in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6680974-76d6-4242-9842-7da0ecec8246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+----------+--------+\n",
      "|user_id_sender|user_id_receiver|      date|  action|\n",
      "+--------------+----------------+----------+--------+\n",
      "|     ad4943sdz|      948ksx123d|2020-01-04|    sent|\n",
      "|     ad4943sdz|      948ksx123d|2020-01-06|accepted|\n",
      "|    dfdfxf9483|      9djjjd9283|2020-01-04|    sent|\n",
      "|    dfdfxf9483|      9djjjd9283|2020-01-15|accepted|\n",
      "| ffdfff4234234|     lpjzjdi4949|2020-01-06|    sent|\n",
      "|   fffkfld9499|     993lsldidif|2020-01-06|    sent|\n",
      "|   fffkfld9499|     993lsldidif|2020-01-10|accepted|\n",
      "|    fg503kdsdd|       ofp049dkd|2020-01-04|    sent|\n",
      "|    fg503kdsdd|       ofp049dkd|2020-01-10|accepted|\n",
      "|    hh643dfert|      847jfkf203|2020-01-04|    sent|\n",
      "|    r4gfgf2344|      234ddr4545|2020-01-06|    sent|\n",
      "|    r4gfgf2344|      234ddr4545|2020-01-11|accepted|\n",
      "+--------------+----------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables_query = \"\"\"SELECT * FROM fb_friend_requests\"\"\"\n",
    "\n",
    "table_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"query\", tables_query) \\\n",
    "    .option(\"user\", connection_properties[\"user\"]) \\\n",
    "    .option(\"password\", connection_properties[\"password\"]) \\\n",
    "    .option(\"driver\", connection_properties[\"driver\"]) \\\n",
    "    .load()\n",
    "\n",
    "table_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66ceb146-3b6f-40c3-aac9-334c371ea7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+----------+------+-----------+\n",
      "|user_id_sender|user_id_receiver|      date|action|next_action|\n",
      "+--------------+----------------+----------+------+-----------+\n",
      "|     ad4943sdz|      948ksx123d|2020-01-04|  sent|   accepted|\n",
      "|    dfdfxf9483|      9djjjd9283|2020-01-04|  sent|   accepted|\n",
      "| ffdfff4234234|     lpjzjdi4949|2020-01-06|  sent|       NULL|\n",
      "|   fffkfld9499|     993lsldidif|2020-01-06|  sent|   accepted|\n",
      "|    fg503kdsdd|       ofp049dkd|2020-01-04|  sent|   accepted|\n",
      "|    hh643dfert|      847jfkf203|2020-01-04|  sent|       NULL|\n",
      "|    r4gfgf2344|      234ddr4545|2020-01-06|  sent|   accepted|\n",
      "+--------------+----------------+----------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Bring the sent and accepted in single row using lead\n",
    "window = Window.partitionBy('user_id_sender').orderBy('date')\n",
    "df = table_df.withColumn('next_action', f.lead('action').over(window))\n",
    "\n",
    "# Consider only row with 'sent'\n",
    "df = df.filter(f.col('action') == 'sent')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3554e829-8826-477d-b1a8-7cd3a229e90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_user_count = df.count()\n",
    "total_user_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4de4d357-8d58-48f2-857a-925973cb02cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_count = df.filter(f.col('next_action') == 'accepted').agg(f.count('*')).collect()[0][0]\n",
    "accepted_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bb74fd1-c357-4e02-8a1c-cb8edf126009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.43"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptance_percentage = round((accepted_count / total_user_count) * 100, 2)\n",
    "acceptance_percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
